Project 2
=========

We will find the most probable **sequence of states** given:

* Sequence of observations
* Transition and sensory probabilites

Using the two algorithms:

* Expectation-Maximization (EM) Algorithm
* Viterbi's Algorithm

Problem Statement
-----------------

Given a structure of the **Hidden Markov Model** and a sequence of observations Heads and Tails generated by 2 coins (one balanced and the other loaded), our task is to **learn transition and sensory probabilites** using **EM algorithm** for HMM and then find the most probable sequence of states (Balanced or Loaded) that generated these observations using the **Viterbi's Algorithm**.

----

Sequence Generator
------------------

> sequence-generator.rb

Syntax for arguments
```
sequence-generator [input_file_name] [sequence_length]
```

This program generates:

* Sequence of States (B for Balanced or L for Loaded)
* Sequence of Observations based on the states (0 for Tails or 1 for Heads)

Length of the sequence can be specified as an argument. Default sequence length is 20.

Program looks for an input file that contains values for the following (in the same order):
B|B, L|B, B|L, L|L, H|B, T|B, H|L, T|L
Input file can be specified as an argument. Default file is hmm.txt

The output file seq.txt. It contains the randomly generated sequence of states on the first line and the sequence of observations in the second line.

----

Expectation-Maximization Algorithm
----------------------------------

> em.rb

Syntax for arguments
```
em [input_file_name]
```
