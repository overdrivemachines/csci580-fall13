Project 2
=========

We will find the most probable **sequence of states** given:

* Sequence of observations
* Transition and sensory probabilites

Using the two algorithms:

* Expectation-Maximization (EM) Algorithm
* Viterbi's Algorithm

Problem Statement
-----------------

Given a structure of the **Hidden Markov Model** and a sequence of observations Heads and Tails generated by 2 coins (one balanced and the other loaded), our task is to **learn transition and sensory probabilites** using **EM algorithm** for HMM and then find the most probable sequence of states (Balanced or Loaded) that generated these observations using the **Viterbi's Algorithm**.

----

